
# =============================
# main_grpo.py (æ”¹è¿›ç‰ˆ)
# å˜åŒ–ç‚¹ï¼š
# 1) æ–°å¢ freeze_manager_backboneã€use_value_baselineã€lambda/value ç³»æ•°ã€manager_token_max_len
# 2) specialist_max_tokens é»˜è®¤ 150
# 3) ä»…è®­ç»ƒ heads çš„è¯´æ˜
# =============================

import torch
import json
import random
import warnings
from manager_agent import ManagerAgent, FixedSpecialistAgent
from grpo_trainer import GRPOTrainer
from utils import LocalHF

warnings.filterwarnings('ignore', message='Attempting to unscale FP16 gradients')

def load_dataset_from_json(path):
    try:
        with open(path, 'r', encoding='utf-8') as f:
            full_data = json.load(f)
    except FileNotFoundError:
        print(f"é”™è¯¯: æ–‡ä»¶ '{path}' æœªæ‰¾åˆ°ã€‚")
        return []
    except json.JSONDecodeError:
        print(f"é”™è¯¯: æ–‡ä»¶ '{path}' ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ–‡ä»¶ã€‚")
        return []

    dataset = []
    for row in full_data:
        dataset.append({
            "problem": row.get("question", ""),
            "context": row.get("context", ""),
            "answer": row.get("ground_truth", "")
        })
    return dataset


def main():
    config = {
        # === 1. æ¨¡å‹è·¯å¾„ ===
        "manager_model_path": "Qwen/Qwen2.5-0.5B-Instruct",
        "specialist_model_path": "Qwen/Qwen2.5-0.5B-Instruct",
        
        # === 2. æ•°æ®è·¯å¾„ ===
        "dataset_path": r"C:\\Users\\yyn07\\Desktop\\multi_agent_test\\Codes\\data\\golden_dataset_pubmedqa_qwen2.5_pro_test_500.json",

        # === 3. è®­ç»ƒè¶…å‚æ•° ===
        "num_epochs": 3,
        "max_steps": 5,
        "manager_lr": 5e-6,  # æ›´ç¨³å¥ï¼ˆåªè®­ headsï¼‰
        "specialist_max_tokens": 150,
        
        # === 4. GRPO å‚æ•° ===
        "num_samples_per_prompt": 4,
        "grpo_epochs": 3,
        "minibatch_size": 8,
        "ent_coef": 0.01,
        "max_grad_norm": 1.0,
        
        # === 5. è¾“å‡ºæ§åˆ¶ ===
        "verbose_trajectory": True,
        "verbose_frequency": 5,
        
        # === 6. æ··åˆç²¾åº¦ ===
        "use_amp": True,
        
        # === 7. å¥–åŠ±ç»´åº¦å’Œåå¥½ ===
        "reward_dims": ["correctness", "efficiency", "quality"],
        "manager_preference": [1.0, 0.1, 0.2],
        
        # === 8. æ•°æ®åˆ’åˆ† ===
        "random_seed": 42,
        "train_ratio": 0.8,
        
        # === 9. Manager è®­ç»ƒèŒƒå›´ä¸ Baseline ===
        "freeze_manager_backbone": True,      # ä»…è®­ç»ƒ heads
        "use_value_baseline": True,           # å¯ç”¨ GRPO-Î» å’Œ value loss
        "lambda_coef": 0.5,                   # GRPO-Î» ä¸­ V çš„æƒé‡
        "value_coef": 0.5,                    # value loss æƒé‡
        "normalize_adv": False,               # æ˜¯å¦æ ‡å‡†åŒ–ç»„ä¼˜åŠ¿
        "manager_token_max_len": 1024,
    }
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    print("="*60)
    print("LOADING AND SPLITTING DATASET")
    print("="*60)
    
    full_dataset = load_dataset_from_json(config['dataset_path'])
    
    if not full_dataset:
        print("é”™è¯¯: æ•°æ®é›†ä¸ºç©º!")
        return
    
    print(f"âœ“ Loaded {len(full_dataset)} samples")
    
    random.seed(config['random_seed'])
    print(f"âœ“ Set random seed to {config['random_seed']}")
    
    shuffled_dataset = full_dataset.copy()
    random.shuffle(shuffled_dataset)
    
    num_train = int(len(shuffled_dataset) * config['train_ratio'])
    train_dataset = shuffled_dataset[:num_train]
    test_dataset = shuffled_dataset[num_train:]
    
    print(f"\nâœ“ Split completed:")
    print(f"  Training set:   {len(train_dataset)} samples")
    print(f"  Test set:       {len(test_dataset)} samples")
    print("="*60)
    
    test_indices_file = "./test_indices_grpo.json"
    with open(test_indices_file, 'w', encoding='utf-8') as f:
        json.dump({
            "random_seed": config['random_seed'],
            "test_samples": [
                {"problem": s["problem"][:100], "answer": s["answer"]} 
                for s in test_dataset
            ]
        }, f, indent=2, ensure_ascii=False)
    print(f"âœ“ Saved test set info to {test_indices_file}\n")

    print("Initializing model backend...")
    specialist_backend = LocalHF(
        config['specialist_model_path'], 
        max_tokens=config['specialist_max_tokens']
    )
    specialist_backend.model.eval()
    for param in specialist_backend.model.parameters():
        param.requires_grad = False
    print("âœ“ Specialist model frozen (no training)")

    print("\nInitializing Manager and Specialists...")
    specialist_names = ["problem_understanding", "reasoning", "computation", "answering"]
    
    manager = ManagerAgent(
        model_path=config['manager_model_path'], 
        specialist_names=specialist_names,
        num_rewards=len(config['reward_dims']),
        freeze_manager_backbone=config['freeze_manager_backbone'],
        manager_token_max_len=config['manager_token_max_len']
    )
    
    print("="*60)
    print("Manager Configuration")
    print("="*60)
    print(f"Specialists: {specialist_names}")
    print(f"Reward dims: {config['reward_dims']}")
    print(f"Preference:  {config['manager_preference']}")
    print(f"Freeze backbone: {config['freeze_manager_backbone']}")
    print(f"Use value baseline: {config['use_value_baseline']} (lambda={config['lambda_coef']}, value_coef={config['value_coef']})")
    print("="*60)
    
    print("\nTesting Manager...")
    test_state = {"problem": "Test: What is 2+2?", "context": ""}
    with torch.no_grad():
        test_action, _, _, _ = manager.act(test_state, [])
        print(f"âœ“ Manager selected: {test_action['specialist_id']}")
    
    specialists = {
        name: FixedSpecialistAgent(agent_name=name, model_backend=specialist_backend)
        for name in specialist_names
    }
    print(f"âœ“ Created {len(specialists)} fixed specialists")

    print("\nInitializing GRPO Trainer...")
    trainer = GRPOTrainer(
        config=config,
        manager=manager,
        specialists=specialists,
        model_backend=specialist_backend,
        train_dataset=train_dataset
    )
    
    print("="*60)
    print("GRPO Configuration")
    print("="*60)
    print(f"Samples per prompt:  {config['num_samples_per_prompt']}")
    print(f"GRPO epochs:         {config['grpo_epochs']}")
    print(f"Manager LR:          {config['manager_lr']}")
    print(f"Minibatch size:      {config['minibatch_size']}")
    print("="*60)

    print("\nğŸš€ Starting GRPO Training...")
    print("ğŸ’¡ Note: Only Manager HEADS are being trained (backbone frozen)\n")
    
    trainer.train()
    
    print("\nğŸ’¾ Saving trained Manager...")
    trainer.save_manager("./trained_manager_grpo")
    print("âœ“ Training completed!")
    
    print("\n" + "="*60)
    print("NEXT STEPS")
    print("="*60)
    print(f"âœ“ Manager saved to: ./trained_manager_grpo")
    print(f"âœ“ Test set info saved to: {test_indices_file}")
    print(f"\nTo evaluate:")
    print(f"  1. Load the trained Manager")
    print(f"  2. Use the test set (last {len(test_dataset)} samples)")
    print(f"  3. Run inference with fixed Specialists")
    print("="*60)


if __name__ == "__main__":
    main()
